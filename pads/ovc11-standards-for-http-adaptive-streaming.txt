== Standards for HTTP Adaptive Streaming

Frank Galligan (Google)
Aaron Colwell (Google)
Mark Watson (Netflix)


=== Mark: Introduction to DASH

* MPEG is finalizing the DASH specification
* DASH is a manifest format for describing all available streams for a media resource
* DASH also defines file formats that are suitable for making use of this with MPEG-4 File Format; transport streams work "magically"
* there is also a common encryption scheme for MPEG-4 file format in DASH
* defined profiles: 2 for mp4, 2 for transport streams
* for transport streams there is a on-demand and a live profile:
  * on-demand profiles require alignment of files
  * live require chunking of the files
* example manifest
  * AdaptationSet: groups per resource or per track
  * Representation: different representations for same resource
  * muxed cases are difficult in particular to align the chunks
* features:
  * multiple tracks / accessibility
  * trick modes (e.g. deal with fast forward by dropping to lower framerate)
  * 3D, multi-view, scalable video
  * protected content
* implementation: Netflix is using this format

Comments:
* the DASH file format is very complex and could be simplified and not require such a complicated parser
* to implement it with Matroska, you will need to extract the Matroska cluster index
* nicely arranged media in chunks and index them (when authoring) really helps to simplify the adaptive streaming
* example bitstreams and implementations are in the process of being developed in MPEG


=== Aaron: Media Source API

* implemented in Chrome for adaptive streaming, but may be applicable to other use cases
* an extension to HTMLMediaElement that allos to pipe data into audio and video, similar to appendBytes in Flash
* stream switching, buffering, delivery, manifest strategies should not be done by the browser - the browser just provides an API to dynamically create content
* supports adaptive streaming, mashups, ad insertion, streaming services, DVR, video editors (constraint editing)
* proposed IDL:

interface HTMLMediaElement : HTMLElement {
    ...
    // URL passed to src attribute to enable the media source logic.
    readonly attribute DOMString webkitMediaSourceURL;

    // Appends media to to the source.
    void webkitSourceAppend(in Uint8Array data) raises (DOMException);

    // Signals the end of stream.
    const unsigned short EOS_NO_ERROR = 0; // End of stream reached w/o error.
    const unsigned short EOS_NETWORK_ERR = 1; // A network error triggered end of stream.
    const unsigned short EOS_DECODE_ERR = 2; // A decode error triggered end of stream.
    void webkitSourceEndOfStream(in unsigned short status) raises (DOMException);

    // Indicates the current state of the media source.
    const unsigned short SOURCE_CLOSED = 0;
    const unsigned short SOURCE_OPEN = 1;
    const unsigned short SOURCE_ENDED = 2;
    readonly attribute unsigned short webkitSourceState;
    ....
};

  * special URL that the browser advertises: webkitMediaSourceURL (media data comes from JS)
  * webkitSourceAppend() call with error handling
  * webkitSourceEdnOfStream with states to manage stage handling
* browser doesn't care how JS gets the seek point and the time stamp - it just allows the JS developer to deal with it
* you would use JS to parse the Ogg packets
* Draft spec available: http://tinyurl.com/3aqpknx
* supports playback of a minimalist WebM byte stream (INFO, TRACKS, CLUSTER)
* supports muxed & demuxed streams
* bulk of code is check into WebKit and Chromium, but #ifdef-ed out; about to add command-line flag
* two demos available: basic VOD  & adaptive streaming

Next steps:
* make byte stream look more like WebM live streams, so JS handling becomes easier
* implement frame size change & possibly Vorbis codebook change support
* publish a byte stream spec for WebM
* release command-line flag in Chrome 16 to encourage demos to iron out issues
* find out how to support MP4 and Ogg with this API
* for Ogg providing an index to simplify seeking would help (this is essentially a shoutcast stream)
* start standardisation discussion at WHATWG


Have break-out group tomorrow about this!!!

Discussion:
* have you considered ad blocking as an application; we expect there will be the jquery equivalent for adaptive streaming
* problem with implementing adaptive streaming in the player is that it is hard to innovate; if we push that into JS, it is easier to improve and allow support; a more fundamental API for how to manipulate video is useful and the browser is just used as a playback engine
* don't use encoded frames, but clusters to deal with larger chunks and make it still performant


=== Frank: adaptive streaming demo

* I have a manifest file in xml, but it could be in JSON
* average bitrates for streams are being shown in video player
* browser downloads and parses manifest, starts with lowest bitrate stream
* demo limits the birate to 1000kbps artificially
* JS gets datarate and decides to switch based on that
* chunks are for video150 frames length (6.25s), audio at 5s
* I'm not switching audio right now
* mediaSource API works on muxed files, so you need unique track IDs
* to start playback, you need to completely download the first chunk

Discussion:
* it would be nice to just have one request per adaptation and then just pull chunks off that same connection; right now every chunk requires another XHR range request
* feels like you're starting to implement a Web browser in JS with XHRs; something with a lower latency might be useful
* originally we wanted to have the browser just deal with the manifest, but we discovered that this is much simpler
* seeking latency is determined by the time it takes to download a whole chunk
* JS devs want early access to data; maybe we can extend XHR to get a stream object

