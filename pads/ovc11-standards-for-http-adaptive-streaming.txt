== Standards for HTTP Adaptive Streaming

Frank Galligan (Google)
Aaron Colwell (Google)
Mark Watson (Netflix)


=== Mark: Introduction to DASH

* MPEG is finalizing the DASH specification
* DASH is a manifest format for describing all available streams for a media resource
* DASH also defines file formats that are suitable for making use of this with MPEG-4 File Format; transport streams work "magically"
* there is also a common encryption scheme for MPEG-4 file format in DASH
* defined profiles: 2 for mp4, 2 for transport streams
* for transport streams there is a on-demand and a live profile:
  * on-demand profiles require alignment of files
  * live require chunking of the files
* example manifest
  * AdaptationSet: groups per resource or per track
  * Representation: different representations for same resource
  * muxed cases are difficult in particular to align the chunks
* features:
  * multiple tracks / accessibility
  * trick modes (e.g. deal with fast forward by dropping to lower framerate)
  * 3D, multi-view, scalable video
  * protected content
* implementation: Netflix is using this format

Comments:
* the DASH file format is very complex and could be simplified and not require such a complicated parser
* to implement it with Matroska, you will need to extract the Matroska cluster index
* nicely arranged media in chunks and index them (when authoring) really helps to simplify the adaptive streaming
* example bitstreams and implementations are in the process of being developed in MPEG


=== Aaron: Media Source API

* implemented in Chrome for adaptive streaming, but may be applicable to other use cases
* an extension to HTMLMediaElement that allos to pipe data into audio and video, similar to appendBytes in Flash
* stream switching, buffering, delivery, manifest strategies should not be done by the browser - the browser just provides an API to dynamically create content
* supports adaptive streaming, mashups, ad insertion, streaming services, DVR, video editors (constraint editing)
* proposed IDL:

interface HTMLMediaElement : HTMLElement {
    ...
    // URL passed to src attribute to enable the media source logic.
    readonly attribute DOMString webkitMediaSourceURL;

    // Appends media to to the source.
    void webkitSourceAppend(in Uint8Array data) raises (DOMException);

    // Signals the end of stream.
    const unsigned short EOS_NO_ERROR = 0; // End of stream reached w/o error.
    const unsigned short EOS_NETWORK_ERR = 1; // A network error triggered end of stream.
    const unsigned short EOS_DECODE_ERR = 2; // A decode error triggered end of stream.
    void webkitSourceEndOfStream(in unsigned short status) raises (DOMException);

    // Indicates the current state of the media source.
    const unsigned short SOURCE_CLOSED = 0;
    const unsigned short SOURCE_OPEN = 1;
    const unsigned short SOURCE_ENDED = 2;
    readonly attribute unsigned short webkitSourceState;
    ....
};

  * special URL that the browser advertises: webkitMediaSourceURL (media data comes from JS)
  * webkitSourceAppend() call with error handling
  * webkitSourceEdnOfStream with states to manage stage handling
* browser doesn't care how JS gets the seek point and the time stamp - it just allows the JS developer to deal with it
* you would use JS to parse the Ogg packets
* Draft spec available: http://tinyurl.com/3aqpknx
* supports playback of a minimalist WebM byte stream (INFO, TRACKS, CLUSTER)
* supports muxed & demuxed streams
* bulk of code is check into WebKit and Chromium, but #ifdef-ed out; about to add command-line flag
* two demos available: basic VOD  & adaptive streaming

Future work:
* make byte stream look more like WebM live streams, so JS handling becomes easier
* 

Have break-out group tomorrow about this!!!



