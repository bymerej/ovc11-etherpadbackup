Helen Nissenbaum

right to privacy is right to control information about yourself
bad idea to make it privacy versus something else

   * that makes it come in the way of something else good

"contextual integrity"

difference of CCTV in a hospital during surgery instead of a public space.

Databases like choicepoint

NYLS has "no camera" parties which indicates a subconsious awareness of visual privacy

Sam

Five Scenario Areas
   * 
   * Facebook Users in the Global North (i.e. USA)
   * The existance of an history that's always on the record has already begun to alter behavior of individuals who now self-censor to ensure that information does not get put up online.

Jillian

Lebanon is more "liberal" country in Arab middle east, has support for gay community
   * Activist in Lebanon stopped worrying about online exposure. 
   * Then learned Mom joined Facebook, changed perspective


i.e. Gay girl in Demascus hoax in Syria -- outed a photo of a lesbian in London without her intention

Film called "What remains of Us" only shown in a theater in Tibet with infrared sensors to make sure nobody was filming.
 * Didn't blur out faces, why? Because the face is the expression. Aesthetics are difficult to balance with anonymity.

Sam -- issues of misappropriation, i.e. Vancouver Riots, people were assumed as criminals for posing in front of vandalism
 * problematic because of issues of due process

i.e. Anonymous arrests -- 22 photo mug shots of those arrested posted by a lawyer pre-trial
 * issue of due process

i.e The "dog poop" lady in South Korea, videos of her letting her dog poop on the subway posted online. She received abuse, death threats etc.
 * * and the dog poop girl was actually the subject of so much public shaming that she withdrew from university -- http://blogoscoped.com/archive/2007-10-15-n68.html

Key questions raised:

1. Helen - What values and purposes underpinning information flow controls are being disrupted by technological changes? What are the privacy harms in different contexts - we need to understand the implementation of these systems in different contexts.

2. If a current problem is the lack of conscious, privacy-minded decision making on the part of users, is the solution to try and get them to make those decisions in an informed way, or should we look for a technical solution that doesn't take as much time and effort? 

3. Given that it is so difficult to retract an online personality (once "out") how can we better protect activists who in their work necessarily have public profiles?

4. Who has the "right" to anonymity?

5. Nathan - there can be aesthetic incompatibilities for storytellers and documentary makers between making human rights cases compelling and powerful and providing complete visual anonymity for activists - are there ways to address this?

6. If your image is collected in connection with a riot/protest/officially surveilled action, how does it impact due process rights to be identified de facto as a "rioter," "protester" or participant? Is this different (or do we think of it differently) in different contexts (from Iran to Vancouver to London)? 


Rich Jones - In favor of more surveillance
 * Surveillance is already happening, it's only going to get worse, the intrusion will increase
   * therefore we need to level the playing field and get the public involved to drive benefits

 * Openwatch -- project for public to monitor authority figures, i.e. cops
   * Majority of people have instant access to cameras
   * Openwatch posts police abuse as well as positive police actions

It's correct, I think, to point out that right now the trend seems to be toward the powerful (and the government in particular) having increased control over their online presence; this in part comes from the connection between resources and control over the direction of innovation.

What are the ways to address some of these issues? What are possible solutions?
 * Public Policy level
   * You should at least have the right to FOIA-like  access on what reports private sources have about you.
     * related to helen nissenbaum's idea of 'information flow' and contextual integrity
       * But not sufficient: imbalance of power still exists when the government/private sources have the entire collection and can aggregate it, when you only have your own.
   * Legal precedent with being forced to hand over encryption key
     * i.e. US v. Fricosu, and it's in the Colorado district court -- https://www.eff.org/press/archives/2011/07/08 
       * she refused to hand over encryption key to her hard drive to the courts, case is pending but she seems to be ??winning?? on grounds of 5th Amendment right against self-incrimination
   * And right now he's talking about Luzerne County, PA and the "kids for cash" scandal -- the law schools in the greater Philly area were following this closely last year :)
   * http://citizensvoice.com/news/ciavarella-timeline-1.1187108#axzz1VINwSG2l
     * raised in the context of publicizing judicial records and court proceedings

 * Corporate Policy level
   * http://my.nameis.me -- Examples of who is harmed by real name policies, campaign to change Google+ policy


 * Cultural level
   * Maybe if more 'shaming' is likely, like in British riots, then the criminal-consequences should change.  If no one wants to be shamed, there can at least be less power by the system
   * changing the way we think of privacy - not a question of whether our data is safe, but to what extent it is safe, for how long. Not up to people to manage their information, requires developments at systematic level to measure risk, understanding who controls
   * 

 * Personal level
   * Understanding risk analysis. Anyone can track you but are they? What are you willing to sacrifice
     * ??Nate from the Guardian Project?? is two degrees from Julian Assange, it's pretty well known but he hasn't been stopped by authorities
   * There are levels of privilege. Some people can get a job and still have party photos
   * If you're in a small town people already know who you are vs. a city.
 * Tech development level
- The people who develop tools and platforms can have a limited understanding of how the technology affects citizens in completely different contexts to the users they imagine they are designing for - particularly for activists in places like Syria for example.
    Any individual intermediary  tends not to consider it their own responsibility to provide for   anonymity/data protection--but when we all have to speak through  intermediaries--usually multiple intermediaries--to speak, and no one  individually feels it is their responsibility, the information  environment is one where free speech is suppressed.

Importance of open data, even when it is sensitive and could impinge on important individual privacy questions - necessary to be able to challenge. The problem is not technology, the problem is vigilante justice.

Could absolute transparency create a different informational norm (that is consistent, with accepted expectations) would this change the apparent tension between due process/privacy and absolute transparency

False public sphere/private sphere dichotomy in the digital age - it is not always clear what information is being shared "publically", which has reverberations in the legal sphere as there is no adequate definitions

For example - recent push by the Philadelphia PD to get private business owners to register their cameras with the police department, essentially using private resources to gather evidence of crimes. The Philly ACLU currently doesn't see a legal problem here (and they're right) but is there an ethical problem? Where's the line between evidence-gathering and privacy violation?

The gray areas where privacy is nuanced creates serious ethical dilemmas, maybe a philosophical question before its a legal question
There is no such thing as digital media content that can be created and shared in a controlled way?

Interesting demonstrations of privacy awareness/personal management
 * Facebook Users' Phone Numbers Exposed by “Evil” App
   * http://mashable.com/2010/05/24/evil-facebook/
 * Hack discovered to allow you to view who Facebook thinks you're stalking
   * http://thekeesh.com/2011/08/who-does-facebook-think-you-are-searching-for/
* Rich Pell and Trevor Paglen at CMU (as the Institute for Applied Autonomy) developed iSee, which was intended to enable users to avoid surveillance by providing maps of camera locations http://www.appliedautonomy.com/isee.html
 * Facebook´s privacy changes - importance of "a right to awareness"
 * Using Google alerts on names too know what is being put out there 
 * Online identity management tools - Is it naive to think that this is a solution given lack of transparency in much broader data surveillance and tracking?
   * Rich Jones - it's naive because public data is just the tip of the iceberg

Here are the session leader bios:

Session Leader BIOS: Visual Privacy? Visual Anonymity? Panel
 
Nathan Freitas has been writing code since he was seven and hasn't stopped looking for difficult problems to solve with software ever since. A lifelong mobile technology enthusiast, his career has included work on academic research projects, popular consumer gadgets, award-winning digital art pieces and groundbreaking technology for activism. He leads the Guardian Project, which aims to create easy to use apps, open-source firmware MODs, and customized, commercial mobile phones that can be used and deployed around the world, by any person looking to protect their communications and personal data from unjust intrusion and monitoring.
 
Sam Gregory helps people use the power of the moving image to create change. He is the Program Director at the human rights organization WITNESS (www.witness.org), where he supervises initiatives that partner on impactful campaigns with grassroots activists using video, and train and support the growing number of video activists to use video safely, effectively and ethically. Within WITNESS ‘Cameras Everywhere’ Leadership Initiative he identifies solutions to the challenges, and ways to capitalize on the opportunities, presented by increasingly ubiquitous video for human rights. Sam has created training tools and programs including the WITNESS Video Advocacy Institute, was lead editor on ‘Video for Change’ (Pluto Press, 2005) and teaches ‘Human Rights Advocacy Using Video and Related Multimedia’ as an Adjunct Lecturer at the Harvard Kennedy School. Sam graduated from the University of Oxford and completed a Masters in Public Policy as a Kennedy Memorial Scholar at Harvard.  
  
James Grimmelmann: I’m an Associate Professor at New York Law School, where I’m affiliated with the Institute for Information Law and Policy.9 I study how the law governing the creation and use of computer software affects individual freedom and the distribution of wealth and power in society. As a lawyer and technologist, I try to help these two groups speak intelligibly to each other. I teach intellectual property and Internet-related subjects.
 
Rich Jones is the founder and director of The OpenWatch Project. He has been involved in Free Culture activism for many years now and manages numerous open source software projects, including the Android BitTorrent Client, Anomos, Cop Recorder and LectureLeaks. He is a graduate of Boston University and has interned at the Berkman Center for Internet and Society at Harvard Law School and was both a student and mentor in Google's Summer of Code program. He is now working on a new start-up project, Gun.io.
 
Helen Nissenbaum is Professor of Media, Culture and Communication, and Computer Science, at New York University, where she is also Senior Faculty Fellow of the Information Law Institute. Her areas of expertise span social, ethical, and political implications of information technology and digital media. Nissenbaum's research publications have appeared in journals of philosophy, politics, law, media studies, information studies, and computer science. She has written and edited four books, including Privacy in Context: Technology, Policy, and the Integrity of Social Life, which was published in 2010 by Stanford University Press. The National Science Foundation, Air Force Office of Scientific Research, Ford Foundation, U.S. Department of Homeland Security, and the U.S. Department of Health and Human Services Office of the National Coordinator have supported her work on privacy, trust online, and security, as well as several studies of values embodied in computer system design, including search engines, digital games, facial recognition technology, and health information systems. 

Nissenbaum holds a Ph.D. in philosophy from Stanford University and a B.A. (Hons) from the University of the Witwatersrand. Before joining the faculty at NYU, she served as Associate Director of the Center for Human Values at Princeton University. 
 
Jillian C. York is the Director for International Freedom of Expression at the Electronic Frontier Foundation. A longtime blogger and activist, Jillian is particularly interested in Internet filtering at the government level, the policing of content in corporate online spaces, and digital activism. She comes to EFF from Harvard’s Berkman Center for Internet & Society where she worked on, among other things, the OpenNet Initiative and Herdict projects.
 
Jillian also writes for and is on the board of directors of Global Voices, and in her rare free time, enjoys travel and yoga. 



